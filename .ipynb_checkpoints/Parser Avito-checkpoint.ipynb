{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfbab2-75cc-4a06-b2cb-142246176b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4bb81-5b0d-43cb-b678-a9687daffefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5886d1-11ce-43b6-9246-502407872483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests import get\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e692e6a-27a8-4850-ae04-416761a1e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_TEMPLATE = 'https://www.avito.ru/all/avtomobili?p='\n",
    "PAUSE_DURATION_SECONDS = 5\n",
    "MAX_PAGES = 100  # Количество страниц для парсинга\n",
    "\n",
    "def parse_page(soup):\n",
    "    car_blocks = soup.find_all('div', class_='iva-item-root-_lk9K photo-slider-slider-S15A_ iva-item-list-rfgcH iva-item-redesign-rop6P iva-item-responsive-_lbhG items-item-My3ih items-listItem-Gd1jN js-catalog-item-enum')\n",
    "\n",
    "    names = []\n",
    "    prices = []\n",
    "    photos = []\n",
    "    descriptions = []\n",
    "    cities = []\n",
    "    ad_ids = [] \n",
    "    ad_descriptions = []  \n",
    "    time_updates = []\n",
    "    parsing_times = []\n",
    "    ad_paths = []\n",
    "\n",
    "    for car in car_blocks:\n",
    "        # текущее время парсинга\n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        parsing_times.append(current_time)\n",
    "        \n",
    "        # Парсинг названия\n",
    "        try:\n",
    "            name_tag = car.find('a', {\"class\": \"styles-module-root-iSkj3 styles-module-root_noVisited-qJP5D\"})\n",
    "            if name_tag and 'title' in name_tag.attrs:\n",
    "                name = name_tag['title'].strip()\n",
    "            else:\n",
    "                name = np.nan\n",
    "        except:\n",
    "            name = np.nan\n",
    "\n",
    "        # Парсинг цены\n",
    "        try:\n",
    "            price_tag = car.find('meta', {\"itemprop\": \"price\"})\n",
    "            if price_tag and 'content' in price_tag.attrs:\n",
    "                price = price_tag['content']\n",
    "            else:\n",
    "                price = np.nan\n",
    "        except:\n",
    "            price = np.nan\n",
    "\n",
    "        # Парсинг фото\n",
    "        try:\n",
    "            photo_tag = car.find('img', {\"class\": \"photo-slider-image-YqMGj\"})\n",
    "            if photo_tag and 'src' in photo_tag.attrs:\n",
    "                photo = photo_tag['src']\n",
    "            else:\n",
    "                photo = np.nan\n",
    "        except:\n",
    "            photo = np.nan\n",
    "       \n",
    "        # Парсинг описания\n",
    "        try:\n",
    "            description_tag = car.find('p', {\"data-marker\": \"item-specific-params\"})\n",
    "            if description_tag:\n",
    "                description = description_tag.text.strip()\n",
    "            else:\n",
    "                description = np.nan\n",
    "        except:\n",
    "            description = np.nan\n",
    "\n",
    "        # Парсинг города и автодилера\n",
    "        try:\n",
    "            city_tags = car.find_all('span', {\"class\": \"styles-module-noAccent-l9CMS\"})\n",
    "            if city_tags:\n",
    "                city = ', '.join([tag.text.strip() for tag in city_tags])\n",
    "            else:\n",
    "                city = np.nan\n",
    "        except:\n",
    "            city = np.nan\n",
    "\n",
    "        # Парсинг ad_id\n",
    "        try:\n",
    "            ad_id = car['data-item-id']  # Извлекаем ad_id из атрибута data-item-id\n",
    "        except:\n",
    "            ad_id = np.nan\n",
    "\n",
    "        # Парсинг ad_description\n",
    "        try:\n",
    "            ad_description_tag = car.find('meta', {\"itemprop\": \"description\"})\n",
    "            if ad_description_tag and 'content' in ad_description_tag.attrs:\n",
    "                ad_description = ad_description_tag['content'].strip().replace('\\n', '')\n",
    "            else:\n",
    "                ad_description = np.nan\n",
    "        except:\n",
    "            ad_description = np.nan\n",
    "\n",
    "         # Парсинг ссылки объявления\n",
    "        try:\n",
    "            ad_path_tag = car.find('a', {\"class\": \"styles-module-root-iSkj3 styles-module-root_noVisited-qJP5D\"})\n",
    "            if ad_path_tag and 'href' in ad_path_tag.attrs:\n",
    "                ad_path = 'https://www.avito.ru'+ ad_path_tag['href'].strip()\n",
    "            else:\n",
    "                ad_path = np.nan\n",
    "        except:\n",
    "            ad_path = np.nan\n",
    "\n",
    "        # Парсинг времени поднятия\n",
    "        try:\n",
    "            time_update_tag = car.find('p', {\"class\": \"styles-module-root-o3j6a styles-module-size_s-xb_uK styles-module-size_s-__aUd stylesMarningNormal-module-root-_BXZU stylesMarningNormal-module-paragraph-s-_lGjQ styles-module-noAccent-l9CMS\"})\n",
    "            if time_update_tag:\n",
    "                time_update_full_text = time_update_tag.text.strip()\n",
    "                # Разделяем текст на слова и берём первые два слова\n",
    "                time_update_words = time_update_full_text.split()\n",
    "                if len(time_update_words) >= 2:\n",
    "                    time_update = ' '.join(time_update_words[:2])\n",
    "                else:\n",
    "                    time_update = time_update_full_text\n",
    "            else:\n",
    "                time_update = np.nan\n",
    "        except:\n",
    "            time_update = np.nan\n",
    "                            \n",
    "        # Добавляем данные в списки\n",
    "        names.append(name)\n",
    "        prices.append(price)\n",
    "        photos.append(photo)\n",
    "        descriptions.append(description)\n",
    "        cities.append(city)\n",
    "        ad_ids.append(ad_id)  # Добавляем ad_id в список\n",
    "        ad_descriptions.append(ad_description)  # Добавляем ad_description в список\n",
    "        time_updates.append(time_update)\n",
    "        ad_paths.append(ad_path)\n",
    "\n",
    "    # Возвращаем DataFrame из спарсенных данных\n",
    "    df_page = pd.DataFrame({\n",
    "        'name': names,\n",
    "        'price': prices,\n",
    "        'photo': photos,\n",
    "        'description': descriptions,\n",
    "        'city': cities,\n",
    "        'ad_id': ad_ids,  \n",
    "        'ad_description': ad_descriptions,\n",
    "        'time_update': time_updates,\n",
    "        'parsing_time': parsing_times,\n",
    "        'ad_path': ad_paths\n",
    "    })\n",
    "\n",
    "    return df_page\n",
    "\n",
    "\n",
    "def main():\n",
    "    all_cars_df = pd.DataFrame()\n",
    "\n",
    "    # Проверяем, существует ли файл с уже спарсенными данными\n",
    "    if os.path.exists('cars_data.csv'):\n",
    "        # Загружаем существующий файл, если он есть\n",
    "        all_cars_df = pd.read_csv('cars_data.csv')\n",
    "\n",
    "    for page_num in range(1, MAX_PAGES + 1):\n",
    "        print(f\"Парсим страницу {page_num}...\")\n",
    "\n",
    "        try:\n",
    "            # Пробуем загрузить страницу\n",
    "            url = URL_TEMPLATE + str(page_num)\n",
    "            driver.get(url)\n",
    "            sleep(PAUSE_DURATION_SECONDS)\n",
    "\n",
    "            # Получаем HTML-код страницы\n",
    "            page_source = driver.page_source\n",
    "\n",
    "            # Парсим HTML с BeautifulSoup\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            # Парсим данные на текущей странице и добавляем их в DataFrame\n",
    "            df_page = parse_page(soup)\n",
    "            all_cars_df = pd.concat([all_cars_df, df_page], ignore_index=True)\n",
    "\n",
    "            # Сохраняем промежуточный результат после каждой страницы\n",
    "            all_cars_df.to_csv('cars_data.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(f\"Ошибка: страница {page_num} не загрузилась, пропускаем...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Произошла ошибка на странице {page_num}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Парсинг завершен.\")\n",
    "    print(all_cars_df.head())  # Для отладки выводим первые строки DataFrame\n",
    "\n",
    "    # Сохраняем итоговый DataFrame\n",
    "    all_cars_df.to_csv('cars_data.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        service = Service(executable_path=ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2e312-b634-4e73-822b-02d9a4decaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразование видимости датафрейма\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb328c-6884-4a01-aee3-a3b956abb1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь сбрасываем эти опции\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.max_colwidth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04c163-7b6b-4146-aa94-d2e40c7ed561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = pd.read_csv('cars_data.csv')\n",
    "df_cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d693d30-f06e-4f6a-a92c-bff098249c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars[['name', 'description', 'city', 'price', 'ad_id', 'ad_description', ]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d6cf6-ce5d-4d0a-b990-b12f61c103e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
