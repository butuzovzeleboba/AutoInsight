{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfbab2-75cc-4a06-b2cb-142246176b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4bb81-5b0d-43cb-b678-a9687daffefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5886d1-11ce-43b6-9246-502407872483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests import get\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e692e6a-27a8-4850-ae04-416761a1e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Парсим страницу 1...\n",
      "Парсим страницу 2...\n",
      "Парсим страницу 3...\n",
      "Парсинг завершен.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Шаблон URL для парсинга\n",
    "URL_TEMPLATE = 'https://www.avito.ru/all/avtomobili?p='\n",
    "PAUSE_DURATION_SECONDS = 4\n",
    "MAX_PAGES = 100  # Количество страниц для парсинга\n",
    "\n",
    "def parse_page(soup):\n",
    "    # Используем частичное совпадение для поиска блока объявления\n",
    "    car_blocks = soup.find_all('div', class_=lambda x: x and 'iva-item-root' in x)\n",
    "\n",
    "    # Инициализация списков для хранения данных\n",
    "    names, prices, photos, descriptions, cities = [], [], [], [], []\n",
    "    ad_ids, ad_descriptions, time_updates, parsing_times, ad_paths = [], [], [], [], []\n",
    "\n",
    "    for car in car_blocks:\n",
    "        # Текущее время парсинга\n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        parsing_times.append(current_time)\n",
    "        \n",
    "        # Парсинг названия\n",
    "        try:\n",
    "            name_tag = car.find('a', class_=lambda x: x and 'styles-module-root' in x)\n",
    "            name = name_tag['title'].strip() if name_tag and 'title' in name_tag.attrs else np.nan\n",
    "        except:\n",
    "            name = np.nan\n",
    "\n",
    "        # Парсинг цены\n",
    "        try:\n",
    "            price_tag = car.find('meta', {\"itemprop\": \"price\"})\n",
    "            price = price_tag['content'] if price_tag and 'content' in price_tag.attrs else np.nan\n",
    "        except:\n",
    "            price = np.nan\n",
    "\n",
    "        # Парсинг фото\n",
    "        try:\n",
    "            photo_tag = car.find('img', class_=lambda x: x and 'photo-slider-image' in x)\n",
    "            photo = photo_tag['src'] if photo_tag and 'src' in photo_tag.attrs else np.nan\n",
    "        except:\n",
    "            photo = np.nan\n",
    "       \n",
    "        # Парсинг описания\n",
    "        try:\n",
    "            description_tag = car.find('p', {\"data-marker\": \"item-specific-params\"})\n",
    "            description = description_tag.text.strip() if description_tag else np.nan\n",
    "        except:\n",
    "            description = np.nan\n",
    "\n",
    "        # Парсинг города и автодилера\n",
    "        try:\n",
    "            city_tags = car.find_all('span', class_=lambda x: x and 'styles-module-noAccent' in x)\n",
    "            city = ', '.join([tag.text.strip() for tag in city_tags]) if city_tags else np.nan\n",
    "        except:\n",
    "            city = np.nan\n",
    "\n",
    "        # Парсинг ad_id\n",
    "        try:\n",
    "            ad_id = car['data-item-id']  # Извлекаем ad_id из атрибута data-item-id\n",
    "        except:\n",
    "            ad_id = np.nan\n",
    "\n",
    "        # Парсинг ad_description\n",
    "        try:\n",
    "            ad_description_tag = car.find('meta', {\"itemprop\": \"description\"})\n",
    "            ad_description = ad_description_tag['content'].strip().replace('\\n', '') if ad_description_tag and 'content' in ad_description_tag.attrs else np.nan\n",
    "        except:\n",
    "            ad_description = np.nan\n",
    "\n",
    "        # Парсинг ссылки объявления\n",
    "        try:\n",
    "            ad_path_tag = car.find('a', class_=lambda x: x and 'styles-module-root' in x)\n",
    "            ad_path = 'https://www.avito.ru' + ad_path_tag['href'].strip() if ad_path_tag and 'href' in ad_path_tag.attrs else np.nan\n",
    "        except:\n",
    "            ad_path = np.nan\n",
    "\n",
    "        # Парсинг времени поднятия\n",
    "        try:\n",
    "            time_update_tag = car.find('p', class_=lambda x: x and 'styles-module-root' in x)\n",
    "            time_update_full_text = time_update_tag.text.strip() if time_update_tag else np.nan\n",
    "            time_update_words = time_update_full_text.split()\n",
    "            time_update = ' '.join(time_update_words[:2]) if len(time_update_words) >= 2 else time_update_full_text\n",
    "        except:\n",
    "            time_update = np.nan\n",
    "                            \n",
    "        # Добавляем данные в списки\n",
    "        names.append(name)\n",
    "        prices.append(price)\n",
    "        photos.append(photo)\n",
    "        descriptions.append(description)\n",
    "        cities.append(city)\n",
    "        ad_ids.append(ad_id)\n",
    "        ad_descriptions.append(ad_description)\n",
    "        time_updates.append(time_update)\n",
    "        ad_paths.append(ad_path)\n",
    "\n",
    "    # Возвращаем DataFrame из спарсенных данных\n",
    "    df_page = pd.DataFrame({\n",
    "        'name': names,\n",
    "        'price': prices,\n",
    "        'photo': photos,\n",
    "        'description': descriptions,\n",
    "        'city': cities,\n",
    "        'ad_id': ad_ids,\n",
    "        'ad_description': ad_descriptions,\n",
    "        'time_update': time_updates,\n",
    "        'parsing_time': parsing_times,\n",
    "        'ad_path': ad_paths\n",
    "    })\n",
    "\n",
    "    return df_page\n",
    "\n",
    "\n",
    "def main():\n",
    "    all_cars_df = pd.DataFrame()\n",
    "\n",
    "    # Проверяем, существует ли файл с уже спарсенными данными\n",
    "    if os.path.exists('cars_data.csv'):\n",
    "        all_cars_df = pd.read_csv('cars_data.csv')\n",
    "\n",
    "    for page_num in range(1, MAX_PAGES + 1):\n",
    "        print(f\"Парсим страницу {page_num}...\")\n",
    "\n",
    "        try:\n",
    "            url = URL_TEMPLATE + str(page_num)\n",
    "            driver.get(url)\n",
    "            sleep(PAUSE_DURATION_SECONDS)\n",
    "\n",
    "            # Получаем HTML-код страницы\n",
    "            page_source = driver.page_source\n",
    "\n",
    "            # Парсим HTML с BeautifulSoup\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            # Парсим данные на текущей странице и добавляем их в DataFrame\n",
    "            df_page = parse_page(soup)\n",
    "            all_cars_df = pd.concat([all_cars_df, df_page], ignore_index=True)\n",
    "            all_cars_df['ad_id'] = all_cars_df['ad_id'].astype('int64')\n",
    "\n",
    "            # Сохраняем промежуточный результат после каждой страницы\n",
    "            all_cars_df.to_csv('cars_data.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(f\"Ошибка: страница {page_num} не загрузилась, пропускаем...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Произошла ошибка на странице {page_num}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Парсинг завершен.\")\n",
    "\n",
    "    # Сохраняем итоговый DataFrame\n",
    "    all_cars_df.to_csv('cars_data.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        service = Service(executable_path=ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2e312-b634-4e73-822b-02d9a4decaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразование видимости датафрейма\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb328c-6884-4a01-aee3-a3b956abb1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь сбрасываем эти опции\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.max_colwidth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04c163-7b6b-4146-aa94-d2e40c7ed561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = pd.read_csv('cars_data.csv')\n",
    "df_cars.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
