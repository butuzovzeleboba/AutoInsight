{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d74ca97b-f3b8-49eb-be3e-347a1961cb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Collecting typing_extensions~=4.9 (from selenium)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.25.0-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/9.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/9.7 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.0/9.7 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.1/9.7 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.2/9.7 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, typing_extensions, pysocks, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.25.0 sortedcontainers-2.4.0 trio-0.27.0 trio-websocket-0.11.1 typing_extensions-4.12.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae3c7f73-3a45-4469-8113-b18f7454a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-managerNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\taras&dina che\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2024.8.30)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a12b701-5036-4bc5-8832-c8b341eae646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests import get\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e3d47-3d35-4820-996f-77980a8edd55",
   "metadata": {},
   "source": [
    "### Вариант с переходом на страницу объявления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ffe90f-274f-4457-a6eb-495333d33b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Парсим страницу 1...\n",
      "Описание не загрузилось.\n",
      "Описание не загрузилось.\n",
      "Парсим страницу 2...\n",
      "Парсим страницу 3...\n",
      "Описание не загрузилось.\n",
      "Парсим страницу 4...\n",
      "Парсим страницу 5...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "URL_TEMPLATE = 'https://auto.ru/cars/all/?page='\n",
    "PAUSE_DURATION_SECONDS = 4\n",
    "PAUSE_DURATION_DESCR_SECONDS = 0.5\n",
    "MAX_PAGES = 99  # Количество страниц для парсинга\n",
    "\n",
    "def parse_ad_details(driver):\n",
    "    \"\"\"Функция для парсинга деталей объявления, включая описание, дату и ID.\"\"\"\n",
    "    try:\n",
    "        # Ожидаем появления блока с описанием объявления\n",
    "        WebDriverWait(driver, PAUSE_DURATION_DESCR_SECONDS).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'CardDescription__text'))\n",
    "        )\n",
    "        # Парсинг описания\n",
    "        description_div = driver.find_element(By.CLASS_NAME, 'CardDescription__text')\n",
    "        description_texts = [span.text.strip().replace(\"\\n\", \", \") for span in description_div.find_elements(By.TAG_NAME, 'span')]\n",
    "        ad_description = ', '.join(description_texts)\n",
    "    except TimeoutException:\n",
    "        ad_description = None\n",
    "\n",
    "    # Парсинг даты размещения объявления\n",
    "    try:\n",
    "        ad_date_div = driver.find_element(By.CLASS_NAME, 'CardHead__creationDate')\n",
    "        ad_date = ad_date_div.text.strip()\n",
    "    except:\n",
    "        ad_date = None\n",
    "\n",
    "    # Парсинг ID объявления\n",
    "    try:\n",
    "        ad_id_div = driver.find_element(By.CLASS_NAME, 'CardHead__id')\n",
    "        ad_id = ad_id_div.text.strip()\n",
    "    except:\n",
    "        ad_id = None\n",
    "\n",
    "    return ad_description, ad_date, ad_id\n",
    "\n",
    "\n",
    "def parse_page(driver, soup):\n",
    "    car_blocks = soup.find_all('div', class_='ListingItem__main')\n",
    "\n",
    "    names = []\n",
    "    descriptions = []\n",
    "    prices = []\n",
    "    ad_descriptions = []\n",
    "    cities = []\n",
    "    parsing_times = []\n",
    "    ad_paths = []\n",
    "    years = []\n",
    "    probegs = []\n",
    "    ad_dates = []\n",
    "    ad_ids = []\n",
    "\n",
    "    for car in car_blocks:\n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        parsing_times.append(current_time)\n",
    "        \n",
    "        # Парсинг названия\n",
    "        try:\n",
    "            name_tag = car.find('a', {\"class\": \"Link ListingItemTitle__link\"})\n",
    "            name = name_tag.text.strip() if name_tag else None\n",
    "        except:\n",
    "            name = None\n",
    "\n",
    "        # Парсинг описания автомобиля\n",
    "        try:\n",
    "            description_tag = car.find_all('div', {\"class\": \"ListingItemTechSummaryDesktop__cell\"})\n",
    "            if description_tag:\n",
    "                description = ', '.join([tag.get_text(strip=True).replace(\"/\", \",\") for tag in description_tag])\n",
    "            else:\n",
    "                description = np.nan\n",
    "        except:\n",
    "            description = np.nan\n",
    "\n",
    "        # Парсинг цены\n",
    "        try:\n",
    "            price_tags = car.find_all('div', {\"class\": \"ListingItem__priceBlock\"})\n",
    "            price = ', '.join([tag.get_text(strip=True).replace(\"\\u00a0\", \" \").replace(\"Купить в кредит\", \"\") for tag in price_tags]) if price_tags else None\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        # Парсинг года и пробега\n",
    "        try:\n",
    "            year_tag = car.find('div', {\"class\": \"ListingItem__year\"})\n",
    "            year = year_tag.text.strip() if year_tag else None\n",
    "        except:\n",
    "            year = None\n",
    "       \n",
    "        try:\n",
    "            probeg_tag = car.find('div', {\"class\": \"ListingItem__kmAge\"})\n",
    "            probeg = probeg_tag.text.strip() if probeg_tag else None\n",
    "        except:\n",
    "            probeg = None\n",
    "\n",
    "        # Парсинг города\n",
    "        try:\n",
    "            city_tag = car.find('span', {\"class\": \"MetroListPlace__regionName MetroListPlace_nbsp\"})\n",
    "            city = city_tag.text.strip() if city_tag else None\n",
    "        except:\n",
    "            city = None\n",
    "\n",
    "        # Парсинг ссылки объявления\n",
    "        try:\n",
    "            ad_path_tag = car.find('a', {\"class\": \"Link ListingItemTitle__link\"})\n",
    "            ad_path = ad_path_tag['href'].strip() if ad_path_tag and 'href' in ad_path_tag.attrs else None\n",
    "        except:\n",
    "            ad_path = None\n",
    "\n",
    "        # Переход по ссылке объявления и парсинг описания, даты и ID объявления\n",
    "        if ad_path:\n",
    "            driver.get(ad_path)\n",
    "            time.sleep(PAUSE_DURATION_DESCR_SECONDS)\n",
    "            ad_description, ad_date, ad_id = parse_ad_details(driver)\n",
    "        else:\n",
    "            ad_description = ad_date = ad_id = None\n",
    "\n",
    "        # Добавляем данные в списки\n",
    "        names.append(name)\n",
    "        prices.append(price)\n",
    "        ad_descriptions.append(ad_description)\n",
    "        cities.append(city)\n",
    "        ad_paths.append(ad_path)\n",
    "        years.append(year)\n",
    "        probegs.append(probeg)\n",
    "        ad_dates.append(ad_date)\n",
    "        ad_ids.append(ad_id)\n",
    "        descriptions.append(description)\n",
    "        \n",
    "\n",
    "    # Создаем DataFrame\n",
    "    df_page = pd.DataFrame({\n",
    "        'name': names,\n",
    "        'price': prices,\n",
    "        'description': descriptions,\n",
    "        'year': years,\n",
    "        'ad_description': ad_descriptions,\n",
    "        'probeg': probegs,\n",
    "        'city': cities,\n",
    "        'parsing_time': parsing_times,\n",
    "        'ad_path': ad_paths,\n",
    "        'ad_date': ad_dates,\n",
    "        'ad_id': ad_ids\n",
    "    })\n",
    "\n",
    "    return df_page\n",
    "\n",
    "\n",
    "def main():\n",
    "    all_cars_df = pd.DataFrame()\n",
    "\n",
    "    # Проверяем, существует ли файл с уже спарсенными данными\n",
    "    if os.path.exists('cars_data_autoru.csv'):\n",
    "        all_cars_df = pd.read_csv('cars_data_autoru.csv')\n",
    "\n",
    "    for page_num in range(1, MAX_PAGES + 1):\n",
    "        print(f\"Парсим страницу {page_num}...\")\n",
    "\n",
    "        try:\n",
    "            url = URL_TEMPLATE + str(page_num)\n",
    "            driver.get(url)\n",
    "            time.sleep(PAUSE_DURATION_SECONDS)\n",
    "\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            # Парсим данные на текущей странице и добавляем их в DataFrame\n",
    "            df_page = parse_page(driver, soup)\n",
    "            all_cars_df = pd.concat([all_cars_df, df_page], ignore_index=True)\n",
    "\n",
    "            # Сохраняем промежуточный результат\n",
    "            all_cars_df.to_csv('cars_data_autoru.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(f\"Страница {page_num} не загрузилась, пропускаем...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка на странице {page_num}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Парсинг завершен.\")\n",
    "    print(all_cars_df.head())\n",
    "    all_cars_df.to_csv('cars_data_autoru.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe016db8-cd31-4580-ab34-f4ace55129a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразование видимости датафрейма\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e39204-00c3-4400-b69f-018e3522eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь сбрасываем эти опции если надо\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.max_colwidth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f29d3-3d6d-40d8-8afb-a011781b6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = pd.read_csv('cars_data_autoru.csv')\n",
    "df_cars.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
